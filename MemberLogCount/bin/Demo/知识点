一、Combiner（非必需）
1、Combiner是一个运行在Map端的“迷你Reduce”过程，它只处理单台机器生成的数据。
2、声明Combiner继承的是Reducer，其方法实现原理和Reduce的实现原理基本相同。
3、使用条件：仅当Reducer输入的键值对类型和Reducer输出的键值对类型一样，并且
计算逻辑不影响最终计算结果时，才可以在MapReduce程序中加入Combiner。

二、Partioner（非必需）
1、Map或Combiner的输出结果会被Partioner均匀地分配到每个Reducer上，Reducer的
	输出结果又会通过OutputFormat解析成特定的格式存储到HDFS上。
2、Partioner组件的功能是让Map对key进行分区，从而将不同的key分发到不同的Reducer中
	以进行处理。
3、Partioner的数量等于Reducer的个数，Reducer的个数可以在驱动类里面通过
	job.setNumReduceTasks设置。
4、自定义Partioner需要继承Partioner<K2,V2>，并且重写getPartioner的实现方法。
* 如果最终结果要输出到多个文件里，那么只需要让getPartioner方法按照一定规则返回0,1,2,3即可。

三、自定义计数器
1、Hadoop自带计算器分类：
	MapReduce任务计数器、文件系统计数器、输入文件计数器、输出文件计数器、作业计数器。
2、自定义计数器有两种实现方式：
（1）、通过Java枚举（enum）类型来定义，一个作业可以定义的枚举类型数量不限，各枚举类型
	包含的字段数量也不限。枚举类型的名称即为组的名称，枚举类型的字段就是计数器的名称。
	使用getCounter()方法获取枚举中字段的值。
（2）、使用动态计数器。Context类中还有一个重载的方法:
	getCounter(String groupName,String countName)
	能够对当前计数器进行动态计数。
3、方法：首先，在Mapper类中定义枚举类型，接着在map函数里调用Context类的getCounter方法，
说明使用了枚举类型的哪个计数器，还需要调用increment()方法进行计数的添加。（计数器不是只能
在Mapper中添加，在Reducer中也可以添加。）


